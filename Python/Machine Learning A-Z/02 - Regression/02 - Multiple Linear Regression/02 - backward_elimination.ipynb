{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multiple Linear Regression",
   "id": "dd01b9ed8437a13b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing the libraries",
   "id": "99dab042d5501f71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:16.808623Z",
     "start_time": "2025-06-26T18:31:15.869046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "id": "58251abdb4f5ed7c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing the dataset",
   "id": "af708241401aae29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:17.072993Z",
     "start_time": "2025-06-26T18:31:17.043147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('50_Startups.csv')\n",
    "df"
   ],
   "id": "5e884153ca4d56c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0   165349.20       136897.80        471784.10    New York  192261.83\n",
       "1   162597.70       151377.59        443898.53  California  191792.06\n",
       "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3   144372.41       118671.85        383199.62    New York  182901.99\n",
       "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
       "5   131876.90        99814.71        362861.36    New York  156991.12\n",
       "6   134615.46       147198.87        127716.82  California  156122.51\n",
       "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
       "8   120542.52       148718.95        311613.29    New York  152211.77\n",
       "9   123334.88       108679.17        304981.62  California  149759.96\n",
       "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
       "11  100671.96        91790.61        249744.55  California  144259.40\n",
       "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
       "13   91992.39       135495.07        252664.93  California  134307.35\n",
       "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
       "15  114523.61       122616.84        261776.23    New York  129917.04\n",
       "16   78013.11       121597.55        264346.06  California  126992.93\n",
       "17   94657.16       145077.58        282574.31    New York  125370.37\n",
       "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
       "19   86419.70       153514.11             0.00    New York  122776.86\n",
       "20   76253.86       113867.30        298664.47  California  118474.03\n",
       "21   78389.47       153773.43        299737.29    New York  111313.02\n",
       "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
       "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
       "24   77044.01        99281.34        140574.81    New York  108552.04\n",
       "25   64664.71       139553.16        137962.62  California  107404.34\n",
       "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
       "27   72107.60       127864.55        353183.81    New York  105008.31\n",
       "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
       "29   65605.48       153032.06        107138.38    New York  101004.64\n",
       "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
       "31   61136.38       152701.92         88218.23    New York   97483.56\n",
       "32   63408.86       129219.61         46085.25  California   97427.84\n",
       "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
       "34   46426.07       157693.92        210797.67  California   96712.80\n",
       "35   46014.02        85047.44        205517.64    New York   96479.51\n",
       "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
       "37   44069.95        51283.14        197029.42  California   89949.14\n",
       "38   20229.59        65947.93        185265.10    New York   81229.06\n",
       "39   38558.51        82982.09        174999.30  California   81005.76\n",
       "40   28754.33       118546.05        172795.67  California   78239.91\n",
       "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
       "42   23640.93        96189.63        148001.11  California   71498.49\n",
       "43   15505.73       127382.30         35534.17    New York   69758.98\n",
       "44   22177.74       154806.14         28334.72  California   65200.33\n",
       "45    1000.23       124153.04          1903.93    New York   64926.08\n",
       "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
       "47       0.00       135426.92             0.00  California   42559.73\n",
       "48     542.05        51743.15             0.00    New York   35673.41\n",
       "49       0.00       116983.80         45173.06  California   14681.40"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>New York</td>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>California</td>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>Florida</td>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>California</td>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>Florida</td>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>California</td>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>Florida</td>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>California</td>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>Florida</td>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>California</td>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>New York</td>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>Florida</td>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>California</td>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>Florida</td>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>Florida</td>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>California</td>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>Florida</td>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>Florida</td>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>New York</td>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>Florida</td>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>California</td>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>Florida</td>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>California</td>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>New York</td>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>Florida</td>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>California</td>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>California</td>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>California</td>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>Florida</td>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>California</td>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>New York</td>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>California</td>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>New York</td>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>Florida</td>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>California</td>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>California</td>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:17.165992Z",
     "start_time": "2025-06-26T18:31:17.152993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ],
   "id": "8c5aa8b7ced4fd23",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Encoding categorical data",
   "id": "9bbe038c120beb20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:18.269376Z",
     "start_time": "2025-06-26T18:31:17.260994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "X"
   ],
   "id": "f83b15c50e006389",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1.0, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [0.0, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [0.0, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [0.0, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [0.0, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1.0, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [0.0, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [0.0, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1.0, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [0.0, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1.0, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [0.0, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1.0, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [0.0, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [0.0, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1.0, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [0.0, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [0.0, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [0.0, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1.0, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [0.0, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [0.0, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [0.0, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [0.0, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1.0, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [0.0, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [0.0, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [0.0, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [0.0, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [0.0, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [0.0, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1.0, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [0.0, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1.0, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [0.0, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [0.0, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1.0, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [0.0, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1.0, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1.0, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [0.0, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1.0, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [0.0, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1.0, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [0.0, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [0.0, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1.0, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [0.0, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [1.0, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Avoiding the Dummy Variable Trap",
   "id": "ab01d0532ac4528e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:18.364822Z",
     "start_time": "2025-06-26T18:31:18.350929Z"
    }
   },
   "cell_type": "code",
   "source": "X = X[:, 1:]",
   "id": "55c5d223f42543dd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting the dataset into the Training set and Test set",
   "id": "46fa3b14afb5e653"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:18.552795Z",
     "start_time": "2025-06-26T18:31:18.538820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ],
   "id": "939dbf6d7a73ed4e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Building the optimal model using Backward Elimination",
   "id": "77b14318d71f78d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:19.073241Z",
     "start_time": "2025-06-26T18:31:18.632778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_train = np.concat([np.ones((X_train.shape[0], 1)), X_train], 1).astype(np.float64)\n",
    "X_train  # alpha = 0.05 (significance)"
   ],
   "id": "4a495f34073d4ddc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n",
       "        1.0305749e+05, 2.1463481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n",
       "        8.5047440e+04, 2.0551764e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n",
       "        1.4413598e+05, 1.3405007e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n",
       "        1.5769392e+05, 2.1079767e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n",
       "        1.1417579e+05, 2.9491957e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n",
       "        1.4553006e+05, 3.2387668e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n",
       "        1.5654742e+05, 2.5651292e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n",
       "        1.2415304e+05, 1.9039300e+03],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n",
       "        5.1743150e+04, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n",
       "        1.5303206e+05, 1.0713838e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n",
       "        1.2261684e+05, 2.6177623e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n",
       "        1.1564128e+05, 9.1131240e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n",
       "        1.2921961e+05, 4.6085250e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n",
       "        1.2159755e+05, 2.6434606e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n",
       "        9.6189630e+04, 1.4800111e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n",
       "        1.1386730e+05, 2.9866447e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n",
       "        1.2738230e+05, 3.5534170e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n",
       "        1.4871895e+05, 3.1161329e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n",
       "        1.3549507e+05, 2.5266493e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n",
       "        1.3955316e+05, 1.3796262e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n",
       "        9.9814710e+04, 3.6286136e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n",
       "        1.4507758e+05, 2.8257431e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n",
       "        1.1854605e+05, 1.7279567e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.1698380e+05, 4.5173060e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n",
       "        1.2732038e+05, 2.4983944e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n",
       "        5.1283140e+04, 1.9702942e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n",
       "        9.9281340e+04, 1.4057481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n",
       "        1.4719887e+05, 1.2771682e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n",
       "        1.0575103e+05, 3.0476873e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n",
       "        1.2705621e+05, 2.0112682e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n",
       "        1.5377343e+05, 2.9973729e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n",
       "        1.5351411e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n",
       "        1.0867917e+05, 3.0498162e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n",
       "        8.2982090e+04, 1.7499930e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n",
       "        1.1581621e+05, 2.9711446e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.3542692e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n",
       "        1.5480614e+05, 2.8334720e+04]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:19.180912Z",
     "start_time": "2025-06-26T18:31:19.153242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_opt = X_train[:, [0, 1, 2, 3, 4, 5]]  # p_max = 2\n",
    "regressor_OLS = sm.OLS(y_train, X_opt).fit()\n",
    "regressor_OLS.summary()"
   ],
   "id": "c7051c65619b6b5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.943\n",
       "Method:                 Least Squares   F-statistic:                     129.7\n",
       "Date:                Fri, 27 Jun 2025   Prob (F-statistic):           3.91e-21\n",
       "Time:                        00:01:19   Log-Likelihood:                -421.10\n",
       "No. Observations:                  40   AIC:                             854.2\n",
       "Df Residuals:                      34   BIC:                             864.3\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.255e+04   8358.538      5.091      0.000    2.56e+04    5.95e+04\n",
       "x1          -959.2842   4038.108     -0.238      0.814   -9165.706    7247.138\n",
       "x2           699.3691   3661.563      0.191      0.850   -6741.822    8140.560\n",
       "x3             0.7735      0.055     14.025      0.000       0.661       0.886\n",
       "x4             0.0329      0.066      0.495      0.624      -0.102       0.168\n",
       "x5             0.0366      0.019      1.884      0.068      -0.003       0.076\n",
       "==============================================================================\n",
       "Omnibus:                       15.823   Durbin-Watson:                   2.468\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               23.231\n",
       "Skew:                          -1.094   Prob(JB):                     9.03e-06\n",
       "Kurtosis:                       6.025   Cond. No.                     1.49e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ],
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.943</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   129.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 27 Jun 2025</td> <th>  Prob (F-statistic):</th> <td>3.91e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:01:19</td>     <th>  Log-Likelihood:    </th> <td> -421.10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   854.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    34</td>      <th>  BIC:               </th> <td>   864.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.255e+04</td> <td> 8358.538</td> <td>    5.091</td> <td> 0.000</td> <td> 2.56e+04</td> <td> 5.95e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -959.2842</td> <td> 4038.108</td> <td>   -0.238</td> <td> 0.814</td> <td>-9165.706</td> <td> 7247.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  699.3691</td> <td> 3661.563</td> <td>    0.191</td> <td> 0.850</td> <td>-6741.822</td> <td> 8140.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.7735</td> <td>    0.055</td> <td>   14.025</td> <td> 0.000</td> <td>    0.661</td> <td>    0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0329</td> <td>    0.066</td> <td>    0.495</td> <td> 0.624</td> <td>   -0.102</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.0366</td> <td>    0.019</td> <td>    1.884</td> <td> 0.068</td> <td>   -0.003</td> <td>    0.076</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15.823</td> <th>  Durbin-Watson:     </th> <td>   2.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  23.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.094</td> <th>  Prob(JB):          </th> <td>9.03e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.025</td> <th>  Cond. No.          </th> <td>1.49e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.49e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.950   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.943   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     129.7   \\\\\n\\textbf{Date:}             & Fri, 27 Jun 2025 & \\textbf{  Prob (F-statistic):} &  3.91e-21   \\\\\n\\textbf{Time:}             &     00:01:19     & \\textbf{  Log-Likelihood:    } &   -421.10   \\\\\n\\textbf{No. Observations:} &          40      & \\textbf{  AIC:               } &     854.2   \\\\\n\\textbf{Df Residuals:}     &          34      & \\textbf{  BIC:               } &     864.3   \\\\\n\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &    4.255e+04  &     8358.538     &     5.091  &         0.000        &     2.56e+04    &     5.95e+04     \\\\\n\\textbf{x1}    &    -959.2842  &     4038.108     &    -0.238  &         0.814        &    -9165.706    &     7247.138     \\\\\n\\textbf{x2}    &     699.3691  &     3661.563     &     0.191  &         0.850        &    -6741.822    &     8140.560     \\\\\n\\textbf{x3}    &       0.7735  &        0.055     &    14.025  &         0.000        &        0.661    &        0.886     \\\\\n\\textbf{x4}    &       0.0329  &        0.066     &     0.495  &         0.624        &       -0.102    &        0.168     \\\\\n\\textbf{x5}    &       0.0366  &        0.019     &     1.884  &         0.068        &       -0.003    &        0.076     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 15.823 & \\textbf{  Durbin-Watson:     } &    2.468  \\\\\n\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   23.231  \\\\\n\\textbf{Skew:}          & -1.094 & \\textbf{  Prob(JB):          } & 9.03e-06  \\\\\n\\textbf{Kurtosis:}      &  6.025 & \\textbf{  Cond. No.          } & 1.49e+06  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The condition number is large, 1.49e+06. This might indicate that there are \\newline\n strong multicollinearity or other numerical problems."
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:19.304428Z",
     "start_time": "2025-06-26T18:31:19.275911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_opt = X_train[:, [0, 1, 3, 4, 5]]  # p_max = 1\n",
    "regressor_OLS = sm.OLS(y_train, X_opt).fit()\n",
    "regressor_OLS.summary()"
   ],
   "id": "d239ecb9a2266c58",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.944\n",
       "Method:                 Least Squares   F-statistic:                     166.7\n",
       "Date:                Fri, 27 Jun 2025   Prob (F-statistic):           2.87e-22\n",
       "Time:                        00:01:19   Log-Likelihood:                -421.12\n",
       "No. Observations:                  40   AIC:                             852.2\n",
       "Df Residuals:                      35   BIC:                             860.7\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.292e+04   8020.397      5.352      0.000    2.66e+04    5.92e+04\n",
       "x1         -1272.1608   3639.780     -0.350      0.729   -8661.308    6116.986\n",
       "x2             0.7754      0.053     14.498      0.000       0.667       0.884\n",
       "x3             0.0319      0.065      0.488      0.629      -0.101       0.165\n",
       "x4             0.0363      0.019      1.902      0.065      -0.002       0.075\n",
       "==============================================================================\n",
       "Omnibus:                       16.074   Durbin-Watson:                   2.467\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.553\n",
       "Skew:                          -1.086   Prob(JB):                     4.66e-06\n",
       "Kurtosis:                       6.164   Cond. No.                     1.43e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.43e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ],
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   166.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 27 Jun 2025</td> <th>  Prob (F-statistic):</th> <td>2.87e-22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:01:19</td>     <th>  Log-Likelihood:    </th> <td> -421.12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   852.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    35</td>      <th>  BIC:               </th> <td>   860.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.292e+04</td> <td> 8020.397</td> <td>    5.352</td> <td> 0.000</td> <td> 2.66e+04</td> <td> 5.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-1272.1608</td> <td> 3639.780</td> <td>   -0.350</td> <td> 0.729</td> <td>-8661.308</td> <td> 6116.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.7754</td> <td>    0.053</td> <td>   14.498</td> <td> 0.000</td> <td>    0.667</td> <td>    0.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0319</td> <td>    0.065</td> <td>    0.488</td> <td> 0.629</td> <td>   -0.101</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.0363</td> <td>    0.019</td> <td>    1.902</td> <td> 0.065</td> <td>   -0.002</td> <td>    0.075</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.074</td> <th>  Durbin-Watson:     </th> <td>   2.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  24.553</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.086</td> <th>  Prob(JB):          </th> <td>4.66e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.164</td> <th>  Cond. No.          </th> <td>1.43e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.43e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.950   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.944   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     166.7   \\\\\n\\textbf{Date:}             & Fri, 27 Jun 2025 & \\textbf{  Prob (F-statistic):} &  2.87e-22   \\\\\n\\textbf{Time:}             &     00:01:19     & \\textbf{  Log-Likelihood:    } &   -421.12   \\\\\n\\textbf{No. Observations:} &          40      & \\textbf{  AIC:               } &     852.2   \\\\\n\\textbf{Df Residuals:}     &          35      & \\textbf{  BIC:               } &     860.7   \\\\\n\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &    4.292e+04  &     8020.397     &     5.352  &         0.000        &     2.66e+04    &     5.92e+04     \\\\\n\\textbf{x1}    &   -1272.1608  &     3639.780     &    -0.350  &         0.729        &    -8661.308    &     6116.986     \\\\\n\\textbf{x2}    &       0.7754  &        0.053     &    14.498  &         0.000        &        0.667    &        0.884     \\\\\n\\textbf{x3}    &       0.0319  &        0.065     &     0.488  &         0.629        &       -0.101    &        0.165     \\\\\n\\textbf{x4}    &       0.0363  &        0.019     &     1.902  &         0.065        &       -0.002    &        0.075     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 16.074 & \\textbf{  Durbin-Watson:     } &    2.467  \\\\\n\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   24.553  \\\\\n\\textbf{Skew:}          & -1.086 & \\textbf{  Prob(JB):          } & 4.66e-06  \\\\\n\\textbf{Kurtosis:}      &  6.164 & \\textbf{  Cond. No.          } & 1.43e+06  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The condition number is large, 1.43e+06. This might indicate that there are \\newline\n strong multicollinearity or other numerical problems."
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:19.430081Z",
     "start_time": "2025-06-26T18:31:19.390560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_opt = X_train[:, [0, 3, 4, 5]]  # p_max = 2\n",
    "regressor_OLS = sm.OLS(y_train, X_opt).fit()\n",
    "regressor_OLS.summary()"
   ],
   "id": "4d1d5f4210202212",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.946\n",
       "Method:                 Least Squares   F-statistic:                     227.8\n",
       "Date:                Fri, 27 Jun 2025   Prob (F-statistic):           1.85e-23\n",
       "Time:                        00:01:19   Log-Likelihood:                -421.19\n",
       "No. Observations:                  40   AIC:                             850.4\n",
       "Df Residuals:                      36   BIC:                             857.1\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.299e+04   7919.773      5.428      0.000    2.69e+04    5.91e+04\n",
       "x1             0.7788      0.052     15.003      0.000       0.674       0.884\n",
       "x2             0.0294      0.064      0.458      0.650      -0.101       0.160\n",
       "x3             0.0347      0.018      1.896      0.066      -0.002       0.072\n",
       "==============================================================================\n",
       "Omnibus:                       15.557   Durbin-Watson:                   2.481\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.539\n",
       "Skew:                          -1.081   Prob(JB):                     1.28e-05\n",
       "Kurtosis:                       5.974   Cond. No.                     1.43e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.43e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ],
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   227.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 27 Jun 2025</td> <th>  Prob (F-statistic):</th> <td>1.85e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:01:19</td>     <th>  Log-Likelihood:    </th> <td> -421.19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   850.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    36</td>      <th>  BIC:               </th> <td>   857.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.299e+04</td> <td> 7919.773</td> <td>    5.428</td> <td> 0.000</td> <td> 2.69e+04</td> <td> 5.91e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7788</td> <td>    0.052</td> <td>   15.003</td> <td> 0.000</td> <td>    0.674</td> <td>    0.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0294</td> <td>    0.064</td> <td>    0.458</td> <td> 0.650</td> <td>   -0.101</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0347</td> <td>    0.018</td> <td>    1.896</td> <td> 0.066</td> <td>   -0.002</td> <td>    0.072</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>15.557</td> <th>  Durbin-Watson:     </th> <td>   2.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  22.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.081</td> <th>  Prob(JB):          </th> <td>1.28e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.974</td> <th>  Cond. No.          </th> <td>1.43e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.43e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.950   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.946   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     227.8   \\\\\n\\textbf{Date:}             & Fri, 27 Jun 2025 & \\textbf{  Prob (F-statistic):} &  1.85e-23   \\\\\n\\textbf{Time:}             &     00:01:19     & \\textbf{  Log-Likelihood:    } &   -421.19   \\\\\n\\textbf{No. Observations:} &          40      & \\textbf{  AIC:               } &     850.4   \\\\\n\\textbf{Df Residuals:}     &          36      & \\textbf{  BIC:               } &     857.1   \\\\\n\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &    4.299e+04  &     7919.773     &     5.428  &         0.000        &     2.69e+04    &     5.91e+04     \\\\\n\\textbf{x1}    &       0.7788  &        0.052     &    15.003  &         0.000        &        0.674    &        0.884     \\\\\n\\textbf{x2}    &       0.0294  &        0.064     &     0.458  &         0.650        &       -0.101    &        0.160     \\\\\n\\textbf{x3}    &       0.0347  &        0.018     &     1.896  &         0.066        &       -0.002    &        0.072     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 15.557 & \\textbf{  Durbin-Watson:     } &    2.481  \\\\\n\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   22.539  \\\\\n\\textbf{Skew:}          & -1.081 & \\textbf{  Prob(JB):          } & 1.28e-05  \\\\\n\\textbf{Kurtosis:}      &  5.974 & \\textbf{  Cond. No.          } & 1.43e+06  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The condition number is large, 1.43e+06. This might indicate that there are \\newline\n strong multicollinearity or other numerical problems."
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:19.508082Z",
     "start_time": "2025-06-26T18:31:19.479082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_opt = X_train[:, [0, 3, 5]]  # p_max = 2\n",
    "regressor_OLS = sm.OLS(y_train, X_opt).fit()\n",
    "regressor_OLS.summary()"
   ],
   "id": "f076c717aa0b3bca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.950\n",
       "Model:                            OLS   Adj. R-squared:                  0.947\n",
       "Method:                 Least Squares   F-statistic:                     349.0\n",
       "Date:                Fri, 27 Jun 2025   Prob (F-statistic):           9.65e-25\n",
       "Time:                        00:01:19   Log-Likelihood:                -421.30\n",
       "No. Observations:                  40   AIC:                             848.6\n",
       "Df Residuals:                      37   BIC:                             853.7\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       4.635e+04   2971.236     15.598      0.000    4.03e+04    5.24e+04\n",
       "x1             0.7886      0.047     16.846      0.000       0.694       0.883\n",
       "x2             0.0326      0.018      1.860      0.071      -0.003       0.068\n",
       "==============================================================================\n",
       "Omnibus:                       14.666   Durbin-Watson:                   2.518\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               20.582\n",
       "Skew:                          -1.030   Prob(JB):                     3.39e-05\n",
       "Kurtosis:                       5.847   Cond. No.                     4.97e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.97e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ],
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   349.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 27 Jun 2025</td> <th>  Prob (F-statistic):</th> <td>9.65e-25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:01:19</td>     <th>  Log-Likelihood:    </th> <td> -421.30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>   848.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    37</td>      <th>  BIC:               </th> <td>   853.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 4.635e+04</td> <td> 2971.236</td> <td>   15.598</td> <td> 0.000</td> <td> 4.03e+04</td> <td> 5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.7886</td> <td>    0.047</td> <td>   16.846</td> <td> 0.000</td> <td>    0.694</td> <td>    0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0326</td> <td>    0.018</td> <td>    1.860</td> <td> 0.071</td> <td>   -0.003</td> <td>    0.068</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.666</td> <th>  Durbin-Watson:     </th> <td>   2.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  20.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.030</td> <th>  Prob(JB):          </th> <td>3.39e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.847</td> <th>  Cond. No.          </th> <td>4.97e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.97e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.950   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.947   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     349.0   \\\\\n\\textbf{Date:}             & Fri, 27 Jun 2025 & \\textbf{  Prob (F-statistic):} &  9.65e-25   \\\\\n\\textbf{Time:}             &     00:01:19     & \\textbf{  Log-Likelihood:    } &   -421.30   \\\\\n\\textbf{No. Observations:} &          40      & \\textbf{  AIC:               } &     848.6   \\\\\n\\textbf{Df Residuals:}     &          37      & \\textbf{  BIC:               } &     853.7   \\\\\n\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &    4.635e+04  &     2971.236     &    15.598  &         0.000        &     4.03e+04    &     5.24e+04     \\\\\n\\textbf{x1}    &       0.7886  &        0.047     &    16.846  &         0.000        &        0.694    &        0.883     \\\\\n\\textbf{x2}    &       0.0326  &        0.018     &     1.860  &         0.071        &       -0.003    &        0.068     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 14.666 & \\textbf{  Durbin-Watson:     } &    2.518  \\\\\n\\textbf{Prob(Omnibus):} &  0.001 & \\textbf{  Jarque-Bera (JB):  } &   20.582  \\\\\n\\textbf{Skew:}          & -1.030 & \\textbf{  Prob(JB):          } & 3.39e-05  \\\\\n\\textbf{Kurtosis:}      &  5.847 & \\textbf{  Cond. No.          } & 4.97e+05  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The condition number is large, 4.97e+05. This might indicate that there are \\newline\n strong multicollinearity or other numerical problems."
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:19.570080Z",
     "start_time": "2025-06-26T18:31:19.558082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = X_train[:, [3]]\n",
    "X_test = X_test[:, [3]]\n",
    "X_train"
   ],
   "id": "80dd4611911be4df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55493.95],\n",
       "       [ 46014.02],\n",
       "       [ 75328.87],\n",
       "       [ 46426.07],\n",
       "       [ 91749.16],\n",
       "       [130298.13],\n",
       "       [119943.24],\n",
       "       [  1000.23],\n",
       "       [   542.05],\n",
       "       [ 65605.48],\n",
       "       [114523.61],\n",
       "       [ 61994.48],\n",
       "       [ 63408.86],\n",
       "       [ 78013.11],\n",
       "       [ 23640.93],\n",
       "       [ 76253.86],\n",
       "       [ 15505.73],\n",
       "       [120542.52],\n",
       "       [ 91992.39],\n",
       "       [ 64664.71],\n",
       "       [131876.9 ],\n",
       "       [ 94657.16],\n",
       "       [ 28754.33],\n",
       "       [     0.  ],\n",
       "       [162597.7 ],\n",
       "       [ 93863.75],\n",
       "       [ 44069.95],\n",
       "       [ 77044.01],\n",
       "       [134615.46],\n",
       "       [ 67532.53],\n",
       "       [ 28663.76],\n",
       "       [ 78389.47],\n",
       "       [ 86419.7 ],\n",
       "       [123334.88],\n",
       "       [ 38558.51],\n",
       "       [  1315.46],\n",
       "       [144372.41],\n",
       "       [165349.2 ],\n",
       "       [     0.  ],\n",
       "       [ 22177.74]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Scaling",
   "id": "176a3adfcec3be0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:19.664078Z",
     "start_time": "2025-06-26T18:31:19.650083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ],
   "id": "4049ac1427b54c0f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training the Multiple Linear Regression model on the Training set",
   "id": "f7e87fe9cce37012"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:19.772660Z",
     "start_time": "2025-06-26T18:31:19.744083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ],
   "id": "879dd82ec070322d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">1e-06</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Predicting the Test set results",
   "id": "35bdd3a017e34e08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T18:31:19.852032Z",
     "start_time": "2025-06-26T18:31:19.838036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_test\": y_test,\n",
    "    \"delta\": y_pred - y_test\n",
    "})"
   ],
   "id": "5e91d53cb411d647",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          y_pred     y_test          delta\n",
       "0  203961.420854  103282.38  100679.040854\n",
       "1  126587.273952  144259.40  -17672.126048\n",
       "2  142600.763270  146121.95   -3521.186730\n",
       "3  120557.920789   77798.83   42759.090789\n",
       "4  134554.154148  191050.39  -56496.235852\n",
       "5  157308.663738  105008.31   52300.353738\n",
       "6  104579.058454   81229.06   23349.998454\n",
       "7  178460.734319   97483.56   80977.174319\n",
       "8  152980.886993  110352.25   42628.636993\n",
       "9  126247.612715  166187.94  -39940.327285"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>203961.420854</td>\n",
       "      <td>103282.38</td>\n",
       "      <td>100679.040854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126587.273952</td>\n",
       "      <td>144259.40</td>\n",
       "      <td>-17672.126048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142600.763270</td>\n",
       "      <td>146121.95</td>\n",
       "      <td>-3521.186730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120557.920789</td>\n",
       "      <td>77798.83</td>\n",
       "      <td>42759.090789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134554.154148</td>\n",
       "      <td>191050.39</td>\n",
       "      <td>-56496.235852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>157308.663738</td>\n",
       "      <td>105008.31</td>\n",
       "      <td>52300.353738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>104579.058454</td>\n",
       "      <td>81229.06</td>\n",
       "      <td>23349.998454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>178460.734319</td>\n",
       "      <td>97483.56</td>\n",
       "      <td>80977.174319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>152980.886993</td>\n",
       "      <td>110352.25</td>\n",
       "      <td>42628.636993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>126247.612715</td>\n",
       "      <td>166187.94</td>\n",
       "      <td>-39940.327285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
